<a name="readme-top"></a>

<div align="center">
  <img src="./assets/ai-researcher.png" alt="Logo" width="400">
  <h1 align="center">AI-Researcher：自主科学创新</h1>
</div>


<div align="center">
  <a href="https://autoresearcher.github.io"><img src="https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&color=FFE165&logo=homepage&logoColor=white" alt="项目页面"></a>
  <a href="https://join.slack.com/t/ai-researchergroup/shared_invite/zt-30y5a070k-C0ajQt1zmVczFnfGkIicvA"><img src="https://img.shields.io/badge/Slack-Join%20Us-red?logo=slack&logoColor=white&style=for-the-badge" alt="加入我们的 Slack 社区"></a>
  <a href="https://discord.gg/zBNYTk5q2g"><img src="https://img.shields.io/badge/Discord-Join%20Us-purple?logo=discord&logoColor=white&style=for-the-badge" alt="加入我们的 Discord 社区"></a>
  <br/>
  <a href="https://autoresearcher.github.io/docs"><img src="https://img.shields.io/badge/Documentation-000?logo=googledocs&logoColor=FFE165&style=for-the-badge" alt="查看文档"></a>
  <a href="https://arxiv.org/abs/2505.18705"><img src="https://img.shields.io/badge/Paper%20on%20Arxiv-000?logoColor=FFE165&logo=arxiv&style=for-the-badge" alt="论文"></a>
  <a href="https://autoresearcher.github.io/leaderboard"><img src="https://img.shields.io/badge/DATASETS-000?logoColor=FFE165&logo=huggingface&style=for-the-badge" alt="基准数据集"></a>
  <hr>
</div>

欢迎来到 **AI-Researcher**🤗。AI-Researcher 在**自动化科学发现**🔬方面带来革命性突破，提出了一个从根本上**重塑传统科研范式**的新系统。该平台具备如下能力：

- 🎯 **完全自主**：端到端的研究自动化
- 🔄 **无缝编排**：从概念到发表一体化流程
- 🧠 **先进 AI 集成**：由尖端 AI 智能体驱动
- 🚀 **加速科研**：高效推进科学创新

--------------------------------------------------------------------------------

✨ AI-Researcher 支持两种层次的用户输入 ✨

**Level 1：详细想法描述**
<br/> 用户提供具体且全面的研究想法描述。系统基于明确需求生成实现方案与执行计划。

**Level 2：基于参考文献的构思**
<br/> 用户仅提交参考论文而不提供具体想法，例如：“我有一些参考论文，请基于这些论文提出创新点并实现”。系统将分析参考文献以生成并发展新的研究构想。

--------------------------------------------------------------------------------

🌟**核心能力与集成**</br>
**AI-Researcher** 通过无缝集成关键组件，构建**完整科研生态**：

🚀**主要研究功能**
- 📚 **文献综述**：对现有研究进行全面分析与综合。
- 📊 **创意生成**：系统化地汇总、组织并提出新的研究方向。
- 🧪 **算法设计与实现**：设计方法并将创意转化为可运行实现。
- 💻 **算法验证与优化**：自动化测试、评估与迭代改进。
- 📈 **结果分析**：对实验数据进行深入解读与洞察。
- ✍️ **论文撰写**：自动生成完整的学术论文。

<div align="center">
  <!-- <img src="./assets/AI-Researchernew-intro.pdf" alt="Logo" width="100%"> -->
  <figure>
    <img src="./assets/AI-Researcher-Framework.png" alt="Logo" style="max-width: 100%; height: auto;">
    <br>
    <figcaption><em>AI-Researcher 概览。</em></figcaption>
  </figure>
</div>


<span id='news'/>

## 🔥 新闻

<div class="scrollable">
  <ul>
    <li><strong>[2025-05-24]</strong>：&nbsp;🎉🎉 <b>重大版本发布！AI-Researcher 全面升级！</b> 🚀
      <br>我们非常高兴地宣布 AI-Researcher 的重要里程碑：
      <ul>
        <li>📄 <b><a href="https://arxiv.org/abs/2505.18705">学术论文发布</a></b>：详述我们的创新方法与实验结果</li>
        <li>📊 <b><a href="https://autoresearcher.github.io/leaderboard">基准套件</a></b>：完整的评测框架与数据集</li>
        <li>🖥️ <b>Web GUI 界面</b>：更便捷地开展研究</li>
      </ul>
      <b>🤝 欢迎加入！</b> 我们欢迎研究者、开发者与 AI 爱好者共同贡献，推进 AI 科研发展。无论是代码、问题反馈、功能建议，还是文档改进，都是宝贵贡献！
      <br>💡 <i>一起打造更聪明的 AI 科研助手！</i>
    </li>
    <li><strong>[2025-03-04]</strong>：&nbsp;🎉🎉我们发布了 <b>AI-Researcher</b>！包含完整框架、数据集、基准构建流水线等。敬请期待更多更新！🚀</li>
  </ul>
</div>

<span id='table-of-contents'/>

## 📑 目录

* <a href='#news'>🔥 新闻</a>
* <a href='#quick-start'>⚡ 快速开始</a>
  * <a href='#installation'>安装</a>
  * <a href='#api-keys-setup'>API 密钥配置</a>
* <a href='#examples'>⬇️ 示例</a>
* <a href='#how-it-works'>✨ 工作原理</a>
* <a href='#how-to-use'>🔍 如何使用</a>
* <a href='#documentation'>📖 文档</a>
* <a href='#community'>🤝 加入社区</a>
* <a href='#acknowledgements'>🙏 致谢</a>
* <a href='#cite'>🌟 引用</a>


<span id='quick-start'/>

## ⚡ 快速开始

<span id='installation'/>

### 安装

#### 本地安装（使用 uv）

1. 使用 [uv](https://docs.astral.sh/uv/)

> 我们推荐使用 [uv](https://docs.astral.sh/uv/) 来管理项目依赖（比 conda 更快）

```bash
# 安装 uv
curl -LsSf https://astral.sh/uv/install.sh | sh
source ~/.bashrc

# 克隆项目
git clone https://github.com/HKUDS/AI-Researcher.git
cd AI-Researcher

# 创建并激活虚拟环境
uv venv --python 3.11
source ./.venv/bin/activate
uv pip install -e .
playwright install
```

#### Docker 安装

为搭建可交互的智能体环境，我们使用 Docker 进行容器化。请先确保系统已安装 [Docker](https://www.docker.com/)。运行研究智能体时，我们使用镜像 `tjbtech1/airesearcher:v1t`。你可以通过以下命令拉取镜像：

```bash
docker pull tjbtech1/airesearcher:v1
```

或者基于我们提供的 [Dockerfile](./docker/Dockerfile) 本地构建：

```bash
cd ./docker && docker build -t tjbtech1/airesearcher:v1 .
```

<span id='api-keys-setup'/>

### API 密钥配置

请基于仓库中的 `.env.template` 创建环境变量文件。在该文件中，配置 API 密钥与测试用例的实例 ID 等参数。

```bash
# ================ 容器配置 ================
# 研究智能体的工作目录名
DOCKER_WORKPLACE_NAME=workplace_paper
# 研究智能体的基础镜像
BASE_IMAGES=tjbtech1/airesearcher:v1
# 补全模型名称，配置详见：https://docs.litellm.ai/docs/
COMPLETION_MODEL=openrouter/google/gemini-2.5-pro-preview-05-20
# 便宜模型名称，配置详见：https://docs.litellm.ai/docs/
CHEEP_MODEL=openrouter/google/gemini-2.5-pro-preview-05-20
# 指定 GPU：
# '"device=0"' 使用第 1 块 GPU
# '"device=0,1"' 使用第 1 与第 2 块 GPU
# '"all"' 使用所有 GPU
# None 表示不使用 GPU
GPUS='"device=0"'
# 容器名称
CONTAINER_NAME=paper_eval
# 工作区名称
WORKPLACE_NAME=workplace
# 缓存路径
CACHE_PATH=cache
# 服务端口
PORT=7020
# 平台
PLATFORM=linux/amd64

# ================ LLM 配置 ================
# GitHub AI Token（示例）
GITHUB_AI_TOKEN=your_github_ai_token
# OpenRouter API Key（示例）
OPENROUTER_API_KEY=your_openrouter_api_key
# OpenRouter API Base URL
OPENROUTER_API_BASE=https://openrouter.ai/api/v1

# ================ 任务配置 ================
# 研究领域类别（对应 ./benchmark/final）：
# diffu_flow | gnn | reasoning | recommendation | vq
# 示例：./benchmark/final/vq
CATEGORY=vq
# 任务实例 ID，例如：./benchmark/final/vq/one_layer_vq.json
INSTANCE_ID=one_layer_vq
# 任务层级：task1 或 task2
TASK_LEVEL=task1
# 最大迭代次数
MAX_ITER_TIMES=0
```

### 🔥 Web GUI

我们提供基于 Gradio 的 Web GUI，运行如下命令即可：

```bash
python web_ai_researcher.py
```

![image-20250606135137558](./assets/webgui/image-20250606135137558.png)

你可以在如下标签页中配置环境变量：

![image-20250606135325373](./assets/webgui/image-20250606135325373.png)

选择示例以运行 AI-Researcher：

<img src="./assets/webgui/image-20250606135507970.png" alt="image-20250606135507970" style="zoom:67%;" />


<span id='examples'/>

## ⬇️ 示例

> ⚠️ 提示：下方 GIF 文件较大，可能需要一定时间加载，请耐心等待其完整渲染。

### 示例 1（向量量化，Vector Quantized）

<details>
  <summary><b>输入：提示（Prompt）</b><br><p>我有一些参考论文，请基于这些论文实现如下想法：</p><ol>
    <li>本文提出的模型旨在通过解决非可微向量量化层的梯度传播问题，提升 VQ-VAE（Vector Quantized Variational AutoEncoder）的性能。</li>...</ol></summary>
<div>
  <ol start="2">
    <li>使用的核心方法包括：
      <ul>
        <li><strong>旋转与缩放变换</strong>：一种线性变换，将编码器输出与最近的码本向量对齐，同时不改变前向传播输出。</li>
        <li><strong>梯度传播方法</strong>：确保梯度从解码器流向编码器，同时保持梯度与码本向量之间的夹角。</li>
        <li><strong>码本管理</strong>：利用编码器输出与对应码本向量之间的联系，缓解码本坍缩并提升利用率。</li>
      </ul>
    </li>
    <li>各组件的主要功能：
      <ul>
        <li>旋转与缩放变换改变编码器输出的量化方式与反向传播中的信息保留方式，使梯度能反映编码器输出相对码本向量的真实位置。</li>
        <li>梯度传播方法重定义通过量化层的梯度回传，从而在训练中获得更优表现。</li>
        <li>码本管理有助于在训练中维持码本多样性，避免多个向量冗余或未被使用。</li>
      </ul>
    </li>
    <li>实现细节：
      <ul>
        <li><strong>关键参数</strong>：
          <ul>
            <li>码本大小需依据数据集复杂度设定（如 1024 或 8192）。</li>
            <li>承诺损失系数（β）通常取值于 [0.25, 2]。</li>
          </ul>
        </li>
        <li><strong>输入/输出规格</strong>：
          <ul>
            <li>编码器输入为连续高维向量，输出为码本中的量化向量。</li>
            <li>重建输出由解码器作用于变换后的码本向量得到。</li>
          </ul>
        </li>
        <li><strong>重要约束</strong>：
          <ul>
            <li>确保码本使用 EMA（指数滑动平均）正确更新；前向时将旋转与缩放对梯度视为常数（停止梯度）。</li>
          </ul>
        </li>
      </ul>
    </li>
    <li>按步骤集成：
      <ul>
        <li><strong>步骤 1</strong>：输入数据向量至编码器，获得连续表征。</li>
        <li><strong>步骤 2</strong>：寻找与编码器输出最近的码本向量。</li>
        <li><strong>步骤 3</strong>：计算将编码器输出对齐到该码本向量的旋转矩阵。</li>
        <li><strong>步骤 4</strong>：应用旋转与缩放变换，得到用于解码器的修改后输出（记为 `˜ q`）。</li>
        <li><strong>步骤 5</strong>：将 `˜ q` 输入解码器，生成重建结果。</li>
        <li><strong>步骤 6</strong>：据重建结果计算损失并反向传播。</li>
        <li><strong>步骤 7</strong>：在反向过程中，以本文方法修改梯度传递，保持夹角，替代传统的梯度近似捷径。</li>
      </ul>
    </li>
    <li>关键实现细节：
      <ul>
        <li>旋转矩阵计算需兼顾效率，可采用 Householder 变换以降低开销。</li>
        <li>通过 stop-gradient 技巧关闭量化层的反向传播，以实现预期的前向改变而不引入梯度噪声。</li>
        <li>训练中定期监控码本使用率，及早发现潜在坍缩并相应调整训练（如学习率）以维持良好利用率。</li>
      </ul>
    </li>
  </ol>
</div>
 </details>

<details>
  <summary><b>输入：参考论文</b><ol>
    <li><strong>Neural discrete representation learning</strong></li>...</ol></summary>
<div>
  <ol start="2">
    <li><strong>Straightening out the straight-through estimator: Overcoming optimization challenges in vector quantized networks</strong></li>
    <li><strong>Estimating or propagating gradients through stochastic neurons for conditional computation</strong></li>
    <li><strong>High-resolution image synthesis with latent diffusion models</strong></li>
    <li><strong>Finite scalar quantization: Vq-vae made simple</strong></li>
    <li><strong>Elements of information theory</strong></li>
    <li><strong>Vector-quantized image modeling with improved vqgan</strong></li>
    <li><strong>Uvim: A unified modeling approach for vision with learned guiding codes</strong></li>
    <li><strong>Auto-encoding variational bayes</strong></li>
    <li><strong>Categorical reparameterization with gumbel-softmax</strong></li>
  </ol>
</div>
</details>

<table>
<tr align="center">
  <td width="50%">
    <a href="./examples/rotation_vq/paper.pdf" target="_blank">
      <img src="./examples/rotation_vq/paper.gif" alt="PDF Document" width="100%"/>
    </a>
    <br>
    <em>自组织论文（由 AI-Researcher 全自动生成，点击查看）。</em>
  </td>
  <td width="50%">
    <a href="./examples/rotation_vq/project" target="_blank">
      <img src="./examples/rotation_vq/scrolling_code.gif" alt="profiles" width="100%"/></a>
    <br>
    <em>自组织工作区，<b>加载较慢</b>（由 AI-Researcher 全自动生成，点击查看）。</em>
  </td>
</tr>
</table>


### 示例 2（类别：向量量化）

<details>
  <summary><b>输入：提示（Prompt）</b><br><p>我有一些参考论文，请基于这些论文实现如下想法：</p><ol>
    <li>该模型聚焦于离散表示学习，适用于图像生成、深度估计、上色、分割等任务，且可与自回归 Transformer 等架构集成。</li>...</ol></summary>
<div>
  <ol start="2">
    <li>核心技术：
      <ul>
        <li><strong>简化量化</strong>：使用标量量化替代 VQ 的简化量化方法。</li>
        <li><strong>维度投影</strong>：定义投影函数将编码器输出映射到可控维度（通常 3–10）。</li>
        <li><strong>梯度传播</strong>：通过 STE（Straight-Through Estimator）穿越量化操作进行梯度传播。</li>
      </ul>
    </li>
    <li>技术组件：
      <ul>
        <li><strong>边界函数</strong>：压缩数据维度并限制值域，如使用 \(f(z) = \left\lfloor \frac{L}{2} \right\rfloor \tanh(z)\) 将数据投影到范围内，\(L\) 为量化级数。</li>
        <li><strong>量化过程</strong>：对每个受限维度取最近整数以得到量化输出。</li>
        <li><strong>损失函数</strong>：采用典型 VAE 重建损失范式优化模型参数。</li>
      </ul>
    </li>
    <li>实现细节：
      <ul>
        <li><strong>关键参数</strong>：
          <ul>
            <li>维度数 \(d\) 与每维级数 \(L\) 依据目标码本规模设定（如令所有 \(L_i \ge 5\)）。</li>
          </ul>
        </li>
        <li><strong>输入/输出规格</strong>：
          <ul>
            <li>边界函数输入为最终编码层输出，量化后输出为 \(\hat{z}\)，形状与原 \(z\) 一致。</li>
          </ul>
        </li>
        <li><strong>约束</strong>：
          <ul>
            <li>确保输入预处理后处于边界函数可用范围。</li>
          </ul>
        </li>
      </ul>
    </li>
    <li>按步骤集成：
      <ul>
        <li><strong>步骤 1</strong>：训练标准 VAE 并获取编码器输出 \(z\)。</li>
        <li><strong>步骤 2</strong>：对 \(z\) 应用边界函数 \(f\)。</li>
        <li><strong>步骤 3</strong>：对受限 \(z\) 执行舍入以得到 \( \hat{z} \)。</li>
        <li><strong>步骤 4</strong>：结合重建损失并使用 STE 回传梯度。</li>
      </ul>
    </li>
    <li>关键实现细节：
      <ul>
        <li>保证舍入过程的可微近似，使用 STE 维持梯度流。</li>
        <li>通过经验选择维度与级数以维持较高码本利用率，并按需监控与调参。</li>
        <li>依据论文设定训练配置（epoch、batch size 等），确保与集成方式匹配。</li>
      </ul>
    </li>
  </ol>
</div>
 </details>

<details>
  <summary><b>输入：参考论文</b><ol>
    <li><strong>Neural discrete representation learning</strong></li>...</ol></summary>
<div>
  <ol start="2">
    <li><strong>Conditional probability models for deep image compression</strong></li>
    <li><strong>High-fidelity generative image compression</strong></li>
    <li><strong>End-to-end optimized image compression</strong></li>
    <li><strong>Taming transformers for high-resolution image generation</strong></li>
    <li><strong>An algorithm for vector quantizer design</strong></li>
    <li><strong>Joint autoregressive and hierarchical priors for learned image compression</strong></li>
    <li><strong>Assessing generative models via precision and recall</strong></li>
    <li><strong>Variational bayes on discrete representation with self-annealed stochastic quantization</strong></li>
    <li><strong>High quality monocular depth estimation via transfer learning</strong></li>
  </ol>
</div>
</details>

<table>
<tr align="center">
  <td width="50%">
    <a href="./examples/fsq/paper.pdf" target="_blank">
      <img src="./examples/fsq/paper.gif" alt="PDF Document" width="100%"/>
    </a>
    <br>
    <em>自组织论文（由 AI-Researcher 全自动生成，点击查看）。</em>
  </td>
  <td width="50%">
    <a href="./examples/fsq/project" target="_blank">
      <img src="./examples/fsq/scrolling_code.gif" alt="profiles" width="100%"/></a>
    <br>
    <em>自组织工作区，<b>加载较慢</b>（由 AI-Researcher 全自动生成，点击查看）。</em>
  </td>
</tr>
</table>

### 示例 3（类别：推荐）

<details>
  <summary><b>输入：提示（Prompt）</b><br><p>我有一些参考论文，请基于这些论文实现如下想法：</p><ol>
    <li>该模型旨在利用异构关系信息提升推荐系统中的用户-物品交互预测。</li>...</ol></summary>
<div>
  <ol start="2">
    <li>核心技术/算法：
      <ul>
        <li><strong>异构图神经网络（GNN）</strong>：用于嵌入初始化与跨不同类型图的消息传播。</li>
        <li><strong>对比学习</strong>：采用跨视图对比框架，使辅助视图与交互视图的嵌入对齐。</li>
        <li><strong>元网络</strong>：提取个性化知识，促进定制化知识迁移。</li>
      </ul>
    </li>
    <li>各组件的作用：
      <ul>
        <li><strong>异构 GNN</strong>：编码用户与物品关系，捕获多种交互语义。</li>
        <li><strong>对比学习</strong>：提供自监督信号，提升表征鲁棒性。</li>
        <li><strong>元网络</strong>：建模个性化特征以实现自适应知识迁移。</li>
      </ul>
    </li>
    <li>实现细节：
      <ul>
        <li><strong>异构 GNN</strong>：
          <ul>
            <li><strong>关键参数</strong>：嵌入初始化使用 Xavier；设定隐藏维度 <code>d</code>。</li>
            <li><strong>输入/输出</strong>：输入为用户-物品、用户-用户、物品-物品的邻接矩阵；输出为关系感知嵌入。</li>
            <li><strong>约束</strong>：能处理不同类型的节点与关系。</li>
          </ul>
        </li>
        <li><strong>对比学习</strong>：
          <ul>
            <li><strong>关键参数</strong>：相似度使用余弦相似度；设置温度系数。</li>
            <li><strong>输入/输出</strong>：输入元网络与用户/物品视图的嵌入；输出对比损失。</li>
            <li><strong>约束</strong>：保持表征多样性以避免过拟合。</li>
          </ul>
        </li>
        <li><strong>元网络</strong>：
          <ul>
            <li><strong>关键参数</strong>：使用带 PReLU 的全连接层生成个性化变换矩阵。</li>
            <li><strong>输入/输出</strong>：输入用户与物品嵌入；输出个性化迁移后的嵌入。</li>
            <li><strong>约束</strong>：采用低秩分解降低参数量。</li>
          </ul>
        </li>
      </ul>
    </li>
    <li>交互流程（步骤）：
      <ul>
        <li>使用异构 GNN 初始化用户与物品嵌入。</li>
        <li>在用户-物品、用户-用户、物品-物品图上进行消息传递、迭代细化嵌入。</li>
        <li>对多视图嵌入做均值池化聚合以保留异构语义。</li>
        <li>提取元知识构建个性化映射函数。</li>
        <li>进行跨视图对齐，得到对比损失。</li>
        <li>将对比损失与 BPR 等配对损失联合优化。</li>
      </ul>
    </li>
    <li>关键实现细节：
      <ul>
        <li>通过实验选择合适的嵌入维度、学习率与 GNN 层数。</li>
        <li>监控过拟合风险，尤其在加深层数或增大维度时。</li>
        <li>确保足够多样的交互模式与有效的数据增强。</li>
      </ul>
    </li>
  </ol>
</div>
 </details>

<details>
  <summary><b>输入：参考论文</b><ol>
    <li><strong>Revisiting Graph Based Collaborative Filtering: A Linear Residual Graph Convolutional Network Approach</strong></li>...</ol></summary>
<div>
  <ol start="2">
    <li><strong>Graph Neural Networks for Social Recommendation</strong></li>
    <li><strong>Improving Graph Collaborative Filtering with Neighborhood-enriched Contrastive Learning</strong></li>
    <li><strong>LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation</strong></li>
    <li><strong>Knowledge-aware Coupled Graph Neural Network for Social Recommendation</strong></li>
    <li><strong>Heterogeneous Graph Transformer</strong></li>
    <li><strong>Sequential Recommendation with Graph Neural Networks</strong></li>
  </ol>
</div>
</details>

<table>
<tr align="center">
  <td width="50%">
    <a href="./examples/hgcl/paper.pdf" target="_blank">
      <img src="./examples/hgcl/paper.gif" alt="PDF Document" width="100%"/>
    </a>
    <br>
    <em>自组织论文（由 AI-Researcher 全自动生成，点击查看）。</em>
  </td>
  <td width="50%">
    <a href="./examples/hgcl/project" target="_blank">
      <img src="./examples/hgcl/scrolling_code.gif" alt="profiles" width="100%"/></a>
    <br>
    <em>自组织工作区，<b>加载较慢</b>（由 AI-Researcher 全自动生成，点击查看）。</em>
  </td>
  </tr>
</table>

### 示例 4（类别：推荐）

<details>
  <summary><b>输入：提示（Prompt）</b><br><p>我有一些参考论文，请基于这些论文实现如下想法：</p><ol>
    <li>该模型关注通过 GNN 与对比学习在稀疏交互场景下的协同过滤。</li>...</ol></summary>
<div>
  <ol start="2">
    <li>核心技术：
      <ul>
        <li><strong>图神经网络</strong>：基于交互图进行消息传递以学习用户与物品嵌入。</li>
        <li><strong>解耦表示</strong>：建模驱动交互的多重潜在意图。</li>
        <li><strong>对比学习</strong>：从增广视图中生成自监督信号。</li>
      </ul>
    </li>
    <li>组件目的：
      <ul>
        <li><strong>GNN 层</strong>：通过迭代消息传递捕获高阶交互。</li>
        <li><strong>意图编码</strong>：区分潜在意图以提升偏好表征。</li>
        <li><strong>自适应增广</strong>：构建兼顾局部与全局的对比视图以提升鲁棒性。</li>
      </ul>
    </li>
    <li>实现细节：
      <ul>
        <li><strong>图构建</strong>：
          <ul>
            <li><strong>输入</strong>：用户-物品交互矩阵 \( A \in \mathbb{R}^{I \times J} \)。</li>
            <li><strong>输出</strong>：归一化邻接矩阵 \( \bar{A} \)。</li>
          </ul>
        </li>
        <li><strong>GNN 配置</strong>：
          <ul>
            <li>层数 \( L \)：通常 2 或 3。</li>
            <li>嵌入维度 \( d \)：可从 \( d=32 \) 起步。</li>
          </ul>
        </li>
        <li><strong>意图原型</strong>：
          <ul>
            <li>意图数 \( K \)：可在 {32, 64, 128, 256} 中实验，建议从 \( K=128 \) 开始。</li>
          </ul>
        </li>
        <li><strong>学习率</strong>：Adam，约 \(1e\!-\!3\)。</li>
        <li><strong>损失函数</strong>：
          <ul>
            <li>推荐主任务使用 BPR。</li>
            <li>自监督使用 InfoNCE，对应本地与全局视图。</li>
          </ul>
        </li>
      </ul>
    </li>
    <li>交互流程：
      <ul>
        <li>由交互矩阵构建图。</li>
        <li>每层 GNN：
          <ul>
            <li>用 \( \bar{A} \) 聚合得到 \( Z(u), Z(v) \)。</li>
            <li>残差更新用户与物品嵌入以避免过平滑。</li>
          </ul>
        </li>
        <li>聚合意图相关表征。</li>
        <li>使用参数化掩码进行自适应增广以形成多视图。</li>
        <li>计算对比损失并与主损失联合优化。</li>
      </ul>
    </li>
    <li>关键实现细节：
      <ul>
        <li>自适应学习增广矩阵以区分交互重要性。</li>
        <li>调节 \( K \) 平衡表达力与噪声。</li>
        <li>用 MAD 指标监测过平滑。</li>
        <li>调节多任务损失权重 \( \lambda_1, \lambda_2, \lambda_3 \)。</li>
      </ul>
    </li>
  </ol>
</div>
 </details>

<details>
  <summary><b>输入：参考论文</b><ol>
    <li><strong>Lightgcn: Simplifying and powering graph convolution network for recommendation</strong></li>...</ol></summary>
<div>
  <ol start="2">
    <li><strong>Neural collaborative filtering</strong></li>
    <li><strong>Disentangled contrastive learning on graphs</strong></li>
    <li><strong>Improving Graph Collaborative Filtering with Neighborhood-enriched Contrastive Learning</strong></li>
    <li><strong>Curriculum Disentangled Recommendation with Noisy Multi-feedback</strong></li>
    <li><strong>Disentangled heterogeneous graph attention network for recommendation</strong></li>
    <li><strong>Learning intents behind interactions with knowledge graph for recommendation</strong></li>
    <li><strong>LightGCL: Simple Yet Effective Graph Contrastive Learning for Recommendation</strong></li>
    <li><strong>Self-supervised graph learning for recommendation</strong></li>
  </ol>
</div>
</details>

<table>
<tr align="center">
  <td width="50%">
    <a href="./examples/dccf/paper.pdf" target="_blank">
      <img src="./examples/dccf/paper.gif" alt="PDF Document" width="100%"/>
    </a>
    <br>
    <em>自组织论文（由 AI-Researcher 全自动生成，点击查看）。</em>
  </td>
  <td width="50%">
    <a href="./examples/dccf/project" target="_blank">
      <img src="./examples/dccf/scrolling_code.gif" alt="profiles" width="100%"/></a>
    <br>
    <em>自组织工作区，<b>加载较慢</b>（由 AI-Researcher 全自动生成，点击查看）。</em>
  </td>
</tr>
</table>

### 示例 5（类别：扩散与流匹配）

<details>
  <summary><b>输入：提示（Prompt）</b><br><p>我有一些参考论文，请基于这些论文实现如下想法：</p><ol>
    <li>该模型基于连续归一化流（CNF）进行生成建模，学习从噪声到数据样本的直线路径。</li>...</ol></summary>
<div>
  <ol start="2">
    <li>架构：
      <ul>
        <li>实现参数化速度场 \( v_{\theta}(t, x) \) 的神经网络。</li>
        <li>使用适合连续函数的结构（如前馈或卷积网络）。</li>
        <li>各层使用非线性激活（ReLU、Tanh 等）。</li>
      </ul>
    </li>
    <li>损失函数：
      <ul>
        <li><strong>速度一致性损失</strong>：
          \[
          L_{\theta} = E_{t \sim U} E_{x_t, x_{t+\Delta t}} 
          \| f_{\theta}(t, x_t) - f_{\theta}(t+\Delta t, x_{t+\Delta t}) \|^2_2 
          + \alpha \| v_{\theta}(t, x_t) - v_{\theta}(t+\Delta t, x_{t+\Delta t}) \|^2_2
          \]
          其中 \( f_{\theta}(t, x_t) = x_t + (1 - t) v_{\theta}(t, x_t) \)。\(\alpha\) 通过验证选择。
        </li>
      </ul>
    </li>
    <li>训练流程：
      <ul>
        <li>从噪声分布 \( p_0 \) 采样 \( x_0 \)。</li>
        <li>划分多个时间段，迭代计算速度场。</li>
        <li>使用 EMA 平滑权重以稳定训练。</li>
      </ul>
    </li>
    <li>采样：
      <ul>
        <li>单步或多步生成：
          \[
          x_{i/k} = x_{(i-1)/k} + \frac{1}{k} v_{i\theta}((i-1)/k, x_{(i-1)/k})
          \]
        </li>
        <li>Euler 方法迭代：
          \[
          x_{t + \Delta t} = x_t + \Delta t \cdot v_i(t, x_t)
          \]
          其中 \( t \in [i/k, (i + 1)/k - \Delta t] \)。
        </li>
      </ul>
    </li>
    <li>关键实现：
      <ul>
        <li>优化器可用 Adam，学习率约 \(2\times 10^{-4}\)。</li>
        <li>批大小据数据集设定（如 CIFAR-10 可用 512）。</li>
        <li>训练与采样均可使用 ODE 求解器（建议 Euler）。</li>
        <li>采样时间 \(U\) 取均匀分布。</li>
      </ul>
    </li>
    <li>性能注意：
      <ul>
        <li>监控收敛并经验验证参数配置；从较少段数开始再逐步增加。</li>
        <li>按收敛稳定性设定 EMA 衰减（常见 0.999）。</li>
        <li>平衡采样效率与样本质量。</li>
      </ul>
    </li>
  </ol>
</div>
 </details>

<details>
  <summary><b>输入：参考论文</b><ol>
    <li><strong>Flow matching for generative modeling</strong></li>...</ol></summary>
<div>
  <ol start="2">
    <li><strong>Consistency models</strong></li>
    <li><strong>Rectified Flow</strong></li>
    <li><strong>Denoising diffusion probabilistic models</strong></li>
    <li><strong>Optimal flow matching: Learning straight trajectories in just one step</strong></li>
    <li><strong>Maximum likelihood training of score-based diffusion models</strong></li>
    <li><strong>Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow</strong></li>
  </ol>
</div>
</details>

<table>
<tr align="center">
  <td width="50%">
    <a href="./examples/con_flowmatching/paper.pdf" target="_blank">
      <img src="./examples/con_flowmatching/paper.gif" alt="PDF Document" width="100%"/>
    </a>
    <br>
    <em>自组织论文（由 AI-Researcher 全自动生成，点击查看）。</em>
  </td>
  <td width="50%">
    <a href="./examples/con_flowmatching/project" target="_blank">
      <img src="./examples/con_flowmatching/scrolling_code.gif" alt="profiles" width="100%"/></a>
    <br>
    <em>自组织工作区，<b>加载较慢</b>（由 AI-Researcher 全自动生成，点击查看）。</em>
  </td>
</tr>
</table>

### 示例 6（类别：图神经网络）

<details>
  <summary><b>输入：提示（Prompt）</b><br><p>我有一些参考论文，请基于这些论文实现如下想法：</p><ol>
    <li>该模型聚焦大图节点分类，解决可扩展性、异配性、长程依赖与缺边等挑战。</li>...</ol></summary>
<div>
  <ol start="2">
    <li>核心技术包括用于全对消息传递的核化 Gumbel-Softmax（复杂度 \(O(N)\)）与 Transformer 风格的逐层潜图学习网络。</li>
    <li>核化 Gumbel-Softmax 近似类别分布以可微学习离散图结构；Transformer 式架构通过潜图实现任意节点对的信息传播。</li>
    <li>实现细节：
      <ul>
        <li><strong>核化 Gumbel-Softmax</strong>：温度 \(\tau\) 常在 0.25–0.4；作用于 \(D\)-维节点特征；输出为邻居选择分布。</li>
        <li><strong>节点特征输入</strong>：每个节点为特征向量，输出为消息传递后的更新嵌入。</li>
        <li><strong>关系偏置（可选）</strong>：基于观测邻接矩阵用激活（如 Sigmoid）调节消息权重。</li>
        <li><strong>边正则损失</strong>：将边概率与监督分类损失结合，鼓励预测边与观测边一致。</li>
      </ul>
    </li>
    <li>交互流程：
      <ul>
        <li>从节点嵌入矩阵 \(X\) 与（可选）邻接矩阵 \(A\) 开始。</li>
        <li>对嵌入应用核化 Gumbel-Softmax 生成邻居选择分布。</li>
        <li>据分布采样邻居并进行消息聚合更新嵌入。</li>
        <li>使用注意力机制更新，可结合关系偏置。</li>
        <li>经过 \(K\) 次采样-传播后，联合监督与边级正则进行优化。</li>
      </ul>
    </li>
    <li>关键实现影响因素：
      <ul>
        <li>谨慎调节 \(\tau\) 以刻画离散结构。</li>
        <li>为大规模图选择合适 batch 与核近似维度。</li>
        <li>使用 dropout 与边级正则提升泛化。</li>
      </ul>
    </li>
  </ol>
</div>
 </details>

<details>
  <summary><b>输入：参考论文</b><ol>
    <li><strong>On the bottleneck of graph neural networks and its practical implications</strong></li>...</ol></summary>
<div>
  <ol start="2">
    <li><strong>Semi-supervised classification with graph convolutional networks</strong></li>
    <li><strong>Categorical reparameterization with gumbel-softmax</strong></li>
    <li><strong>Learning discrete structures for graph neural networks</strong></li>
    <li><strong>Mixhop: Higher-order graph convolutional architectures via sparsified neighborhood mixing</strong></li>
    <li><strong>Graph attention networks</strong></li>
    <li><strong>Geometric deep learning: going beyond euclidean data</strong></li>
    <li><strong>Graph structure learning for robust graph neural networks</strong></li>
    <li><strong>Geom-gcn: Geometric graph convolutional networks</strong></li>
    <li><strong>New benchmarks for learning on non-homophilous graphs</strong></li>
    <li><strong>Latent patient network learning for automatic diagnosis</strong></li>
    <li><strong>Few-shot learning with graph neural networks</strong></li>
    <li><strong>The graph neural network model</strong></li>
    <li><strong>Characteristic functions on graphs: Birds of a feather, from statistical descriptors to parametric models</strong></li>
    <li><strong>Beyond homophily in graph neural networks: Current limitations and effective designs</strong></li>
  </ol>
</div>
</details>

<table>
<tr align="center">
  <td width="50%">
    <a href="./examples/gnn_nodeformer/paper.pdf" target="_blank">
      <img src="./examples/gnn_nodeformer/paper.gif" alt="PDF Document" width="100%"/>
    </a>
    <br>
    <em>自组织论文（由 AI-Researcher 全自动生成，点击查看）。</em>
  </td>
  <td width="50%">
    <a href="./examples/gnn_nodeformer/project" target="_blank">
      <img src="./examples/gnn_nodeformer/scrolling_code.gif" alt="profiles" width="100%"/></a>
    <br>
    <em>自组织工作区，<b>加载较慢</b>（由 AI-Researcher 全自动生成，点击查看）。</em>
  </td>
</tr>
</table>

### 示例 7（类别：图神经网络）

<details>
  <summary><b>输入：提示（Prompt）</b><br><p>我有一些参考论文，请基于这些论文实现如下想法：</p><ol>
    <li>该方法用于在关系不完整或不可靠的数据中挖掘依赖并学习实例表示，适用于半监督节点分类、图像/文本分类、时空预测等。</li>...</ol></summary>
<div>
  <ol start="2">
    <li>核心技术/算法包括受能量约束的扩散模型（以 PDE 表示）、显式 Euler 数值方案与基于能量函数的自适应扩散率函数；模型采用扩散式 Transformer 框架实现全对特征传播。</li>
    <li>主要技术组件目的：
      <ul>
        <li><strong>扩散过程</strong>：通过建模信息流将实例编码为演化状态，揭示实例间关系。</li>
        <li><strong>能量函数</strong>：正则扩散过程，引导表示收敛到低能嵌入以提高质量。</li>
        <li><strong>扩散率函数</strong>：按实例状态自适应指定信息流强度，实现灵活高效传播。</li>
      </ul>
    </li>
    <li>实现细节：
      <ul>
        <li><strong>扩散输入</strong>：批量实例矩阵 \(N\times D\)。</li>
        <li><strong>扩散输出</strong>：\(K\) 次传播后的更新表示；步长 \(\tau\in(0,1)\)。</li>
        <li><strong>能量函数</strong>：\(E(Z, k; \delta) = \|\!|Z - Z^{(k)}\|\!|^2_F + \lambda \sum_{i,j} \delta(\|z_i - z_j\|^2_2)\)，\(\delta\) 单调不减且凹。</li>
        <li><strong>关键参数</strong>：步长 \(\tau\)、层数 \(K\)、正则权重 \(\lambda\)。</li>
      </ul>
    </li>
    <li>步骤交互：
      <ul>
        <li>初始化实例表示。</li>
        <li>每层根据当前嵌入计算扩散率 \(S(k)\)（由函数 \(f\) 给出）。</li>
        <li>按扩散方程更新表示，保持守恒并按 \(S(k)\) 传播。</li>
        <li>\(K\) 层后使用输出层得到预测 logits。</li>
      </ul>
    </li>
    <li>关键实现细节：
      <ul>
        <li>扩散率函数 \(f\) 的选择强烈影响对复杂依赖的建模能力。</li>
        <li>合理设定 \(\tau\) 与 \(\lambda\) 平衡收敛与表示质量；较小 \(\tau\) 需要更深层。</li>
        <li>学习率与早停尤为重要，尤其在大规模数据上。</li>
      </ul>
    </li>
  </ol>
</div>
 </details>

<details>
  <summary><b>输入：参考论文</b><ol>
    <li><strong>Diffusion-convolutional neural networks</strong></li>...</ol></summary>
<div>
  <ol start="2">
    <li><strong>Semi-supervised classification with graph convolutional networks</strong></li>
    <li><strong>Manifold regularization: A geometric framework for learning from labeled and unlabeled examples</strong></li>
    <li><strong>Geometric deep learning: going beyond euclidean data</strong></li>
    <li><strong>Artificial neural networks for solving ordinary and partial differential equations</strong></li>
    <li><strong>Scaling graph neural networks with approximate pagerank</strong></li>
    <li><strong>Learning discrete structures for graph neural networks</strong></li>
    <li><strong>Semi-supervised learning using gaussian fields and harmonic functions</strong></li>
    <li><strong>Graph convolutional networks</strong></li>
    <li><strong>Deep learning via semi-supervised embedding</strong></li>
    <li><strong>A generalization of transformer networks to graphs</strong></li>
    <li><strong>Graph Convolution and Quadratic Time Complexity</strong></li>
    <li><strong>Bayesian graph convolutional neural networks for semi-supervised classification</strong></li>
    <li><strong>Do transformers really perform bad for graph representation?</strong></li>
    <li><strong>Big bird: Transformers for longer sequences</strong></li>
    <li><strong>Adaptive graph diffusion networks</strong></li>
    <li><strong>Transformers are RNNs</strong></li>
    <li><strong>Collective classification in network data</strong></li>
    <li><strong>NodeFormer: A scalable graph structure learning transformer for node classification</strong></li>
  </ol>
</div>
</details>

<table>
<tr align="center">
  <td width="50%">
    <a href="./examples/gnn_difformer/paper.pdf" target="_blank">
      <img src="./examples/gnn_difformer/paper.gif" alt="PDF Document" width="100%"/>
    </a>
    <br>
    <em>自组织论文（由 AI-Researcher 全自动生成，点击查看）。</em>
  </td>
  <td width="50%">
    <a href="./examples/gnn_difformer/project" target="_blank">
      <img src="./examples/gnn_difformer/scrolling_code.gif" alt="profiles" width="100%"/></a>
    <br>
    <em>自组织工作区，<b>加载较慢</b>（由 AI-Researcher 全自动生成，点击查看）。</em>
  </td>
</tr>
</table>


<span id='how-it-works'/>

## ✨ 工作原理（How AI-Researcher works）

* 🔄 **端到端科研自动化系统**
  <br>我们的 **AI-Researcher** 通过集成流水线，为完整科研生命周期提供自动化编排，覆盖三个阶段：
  1. **文献综述与创意生成** 📚💡
     * 🔍 **资源收集器**：自动从主流学术数据库（如 arXiv、IEEE Xplore、ACM Digital Library、Google Scholar）、代码平台（如 GitHub、Hugging Face）与开放数据集收集跨领域材料。
     
     * 🧠 **资源筛选器**：依据质量指标（引用量、代码维护度、数据完整性等）与相关性评估，选择高影响力论文、优质代码与基准数据。
     
     * 💭 **创意生成器**：基于高影响论文与仓库系统化提出新方向；自动评估方法局限、梳理趋势、探索空白点。
  
  2. **新算法设计、实现与验证** 🧪💻
     <br>**设计 → 实现 → 验证 → 优化**
     * 📝 **设计阶段**：形成新算法想法与理论基础，规划实现路线，在可行性与创新性间平衡。
     
     * ⚙️ **实现阶段**：将概念转化为代码，开发模块、搭建测试环境与实验基础设施。
  
     * 🔬 **验证阶段**：系统化实验，评估性能与记录结果，确保实现与需求一致。
       
     * 🔧 **优化阶段** 🔬：依据验证结果迭代优化，定位瓶颈并改进效率，规划下一轮迭代。
  
  3. **论文撰写** ✍️📝
     * **写作智能体** 📄：整合研究动机、算法框架与验证表现，采用分层写作自动生成完整学术论文。

🚀 该系统在整个科研生命周期内尽量减少人工干预，实现从概念到发表的自动化科学发现，是研究者的高效助手。

--------------------------------------------------------------------------------

* 🔬 **全面的基准套件**
  <br>我们构建了系统而标准的评估框架，用于客观评测 AI 研究者的学术能力与科研产出质量，并引入多项创新以确保全面可靠：

  1. 👨‍🔬 **专家级“真值”**：以人类专家撰写的论文作为对照标准，提供高质量参考。

  2. 🌈 **多领域覆盖**：覆盖计算机视觉（CV）、自然语言处理（NLP）、数据挖掘（DM）、信息检索（IR）四大领域。

  3. 🌐 **基准构建全流程开源**：公开数据处理方法、采集流水线与处理代码，确保评测透明，并支持社区按需定制面向不同领域的基准。
    
  4. 📊 **全面评测指标**：采用分层系统化评测，任务按“是否提供想法”分两级；由专业“评审智能体”在多维度打分，包括：1）**新颖性**；2）**实验完备性**；3）**理论基础**；4）**结果分析**；5）**写作质量**。

🚀 **推动科研自动化**。该基准为评测研究自动化能力提供客观框架，支持持续演进与扩展。

--------------------------------------------------------------------------------

* 🌟 **易用的 AI 科研助手**
  <br>**AI-Researcher** 提供丝滑易用的自动化体验，让用户聚焦创新、告别繁杂配置：
  
  1. 🌐 **多 LLM 提供商支持**：可无缝集成 Claude、OpenAI、DeepSeek 等模型，按需选择。
  
  2. 📚 **零门槛启动**：只需提供相关论文清单即可——无需上传文件、无需先给想法、无需复杂配置。
  
  3. 🧠 **最低领域门槛**：自动识别研究空白、提出创新并执行全流程；不同背景用户均可高效产出。
  
  4. 📦 **开箱即用**：最小化配置，立即获得高阶能力，加速科研过程。

<span id='how-to-use'/>

## 🔍 如何使用 AI-Researcher

### 1. Research Agent（研究智能体）

若你已提供具体想法（Level 1 任务），并希望进行广泛调研与实验，可在 [`research_agent/run_infer_level_1.sh`](./research_agent/run_infer_level_1.sh) 中使用如下命令：

```bash
current_dir=$(dirname "$(readlink -f "$0")")
cd $current_dir
export DOCKER_WORKPLACE_NAME=workplace_paper

export BASE_IMAGES=tjbtech1/paperagent:latest

export COMPLETION_MODEL=claude-3-5-sonnet-20241022
export CHEEP_MODEL=claude-3-5-haiku-20241022

category=vq
instance_id=one_layer_vq
export GPUS='"device=0,1"'

python run_infer_plan.py --instance_path ../benchmark/final/${category}/${instance_id}.json --container_name paper_eval --task_level task1 --model $COMPLETION_MODEL --workplace_name workplace --cache_path cache --port 12372 --max_iter_times 0 --category ${category}
```

若你只想提供参考论文，并由研究智能体先生成想法再开展实验（Level 2 任务），可在 [`research_agent/run_infer_level_2.sh`](./research_agent/run_infer_level_2.sh) 中使用：

```bash
current_dir=$(dirname "$(readlink -f "$0")")
cd $current_dir
export DOCKER_WORKPLACE_NAME=workplace_paper

export BASE_IMAGES=tjbtech1/paperagent:latest

export COMPLETION_MODEL=claude-3-5-sonnet-20241022
export CHEEP_MODEL=claude-3-5-haiku-20241022

category=vq
instance_id=one_layer_vq
export GPUS='"device=0,1"'

python run_infer_idea.py --instance_path ../benchmark/final/${category}/${instance_id}.json --container_name paper_eval --model $COMPLETION_MODEL --workplace_name workplace --cache_path cache --port 12372 --max_iter_times 0 --category ${category}
```

### 2. Paper Writing Agent（论文写作智能体）

当研究智能体完成研究后，如需自动生成论文，可在 [`paper_agent/run_infer.sh`](./paper_agent/run_paper.sh) 中使用：

```bash
#!/bin/bash

cd path/to/AI-Researcher/paper_agent

export OPENAI_API_KEY=sk-SKlupNntta4WPmvDCRo7uuPbYGwOnUQcb25Twn8c718tPpXN


research_field=vq
instance_id=rotated_vq

python path/to/AI-Researcher/paper_agent/writing.py --research_field ${research_field} --instance_id ${instance_id}
```

### 3. 基准数据与收集流程

我们的基准已完整开源：

* 详细的基准数据见 [`benchmark`](./benchmark) 目录。
* 详细的基准构建与收集流程见 [`benchmark_collection`](./benchmark_collection) 目录。

<span id='documentation'/>

## 📖 文档

完整文档正在路上 🚀！请关注我们的文档页面：[Documentation](https://auto-researcher.github.io/docs)。

<span id='community'/>

## 🤝 加入社区

我们希望打造一个充满活力的 AI-Researcher 社区，欢迎你的加入：

- [加入 Slack 工作区](https://join.slack.com/t/ai-researchergroup/shared_invite/zt-30y5a070k-C0ajQt1zmVczFnfGkIicvA) —— 讨论研究、架构与未来规划。
- [加入 Discord 服务器](https://discord.gg/ghSnKGkq) —— 社区主导的交流、问答与反馈平台。
- [GitHub Issues](https://github.com/HKUDS/AI-Researcher/issues) —— 查看正在进行的 issue，或提交你的想法。


## 杂项

<div align="center">

[![Stargazers repo roster for @HKUDS/AI-Researcher](https://reporoster.com/stars/HKUDS/AI-Researcher)](https://github.com/HKUDS/AI-Researcher/stargazers)

[![Forkers repo roster for @HKUDS/AI-Researcher](https://reporoster.com/forks/HKUDS/AI-Researcher)](https://github.com/HKUDS/AI-Researcher/network/members)

[![Star History Chart](https://api.star-history.com/svg?repos=HKUDS/AI-Researcher&type=Date)](https://star-history.com/#HKUDS/AI-Researcher&Date)

</div>


<span id='cite'/>

## 🌟 引用

更详细的技术报告即将发布 🚀：

```tex
@misc{airesearcher,
      title={{AI-Researcher: Autonomous Scientific Innovation}},
      author={Jiabin Tang, Lianghao Xia, Zhonghang Li, Chao Huang},
      year={2025},
      eprint={2505.18705},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2505.18705},
}
```


